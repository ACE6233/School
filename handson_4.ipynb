{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ACE6233/School/blob/main/handson_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfdjUnFEhSpV"
      },
      "source": [
        "## Hands-on 4\n",
        "#### The objective of this hands-on is to use YOLOv3 to detect a specified object in a given image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h3w4VvhYTKjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf722f8-8c26-4b20-8ff9-5db03c19924e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading YOLOv3 weights and configuration files...\n",
            "--2025-09-16 11:39:26--  https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov3.weights\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/75388965/e42c2500-9016-11ea-92ba-11df9f79f31b?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-09-16T12%3A19%3A27Z&rscd=attachment%3B+filename%3Dyolov3.weights&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-09-16T11%3A18%3A32Z&ske=2025-09-16T12%3A19%3A27Z&sks=b&skv=2018-11-09&sig=z%2Flr28Z0phL04H7VYqsQPL50NwRPmymI3JEQlBs5xfo%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1ODAyMzA2NiwibmJmIjoxNzU4MDIyNzY2LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.scVEclTDb_sHDtEDVZo3mfH4_DD9Sg6oaBA45-VhoaQ&response-content-disposition=attachment%3B%20filename%3Dyolov3.weights&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-09-16 11:39:26--  https://release-assets.githubusercontent.com/github-production-release-asset/75388965/e42c2500-9016-11ea-92ba-11df9f79f31b?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-09-16T12%3A19%3A27Z&rscd=attachment%3B+filename%3Dyolov3.weights&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-09-16T11%3A18%3A32Z&ske=2025-09-16T12%3A19%3A27Z&sks=b&skv=2018-11-09&sig=z%2Flr28Z0phL04H7VYqsQPL50NwRPmymI3JEQlBs5xfo%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1ODAyMzA2NiwibmJmIjoxNzU4MDIyNzY2LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.scVEclTDb_sHDtEDVZo3mfH4_DD9Sg6oaBA45-VhoaQ&response-content-disposition=attachment%3B%20filename%3Dyolov3.weights&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M  39.7MB/s    in 5.6s    \n",
            "\n",
            "2025-09-16 11:39:32 (42.2 MB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n",
            "\n",
            "--2025-09-16 11:39:32--  https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8342 (8.1K) [text/plain]\n",
            "Saving to: ‘yolov3.cfg’\n",
            "\n",
            "yolov3.cfg          100%[===================>]   8.15K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-09-16 11:39:32 (15.2 MB/s) - ‘yolov3.cfg’ saved [8342/8342]\n",
            "\n",
            "--2025-09-16 11:39:32--  https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 625 [text/plain]\n",
            "Saving to: ‘coco.names’\n",
            "\n",
            "coco.names          100%[===================>]     625  --.-KB/s    in 0s      \n",
            "\n",
            "2025-09-16 11:39:32 (51.2 MB/s) - ‘coco.names’ saved [625/625]\n",
            "\n",
            "Download complete.\n",
            "YOLO model loaded. Supported classes: 80\n",
            "\n",
            "--- List of 80 objects that can be detected by this YOLO model (COCO dataset) ---\n",
            "  1. person           2. bicycle          3. car              4. motorbike      \n",
            "  5. aeroplane        6. bus              7. train            8. truck          \n",
            "  9. boat            10. traffic light   11. fire hydrant    12. stop sign      \n",
            " 13. parking meter   14. bench           15. bird            16. cat            \n",
            " 17. dog             18. horse           19. sheep           20. cow            \n",
            " 21. elephant        22. bear            23. zebra           24. giraffe        \n",
            " 25. backpack        26. umbrella        27. handbag         28. tie            \n",
            " 29. suitcase        30. frisbee         31. skis            32. snowboard      \n",
            " 33. sports ball     34. kite            35. baseball bat    36. baseball glove \n",
            " 37. skateboard      38. surfboard       39. tennis racket   40. bottle         \n",
            " 41. wine glass      42. cup             43. fork            44. knife          \n",
            " 45. spoon           46. bowl            47. banana          48. apple          \n",
            " 49. sandwich        50. orange          51. broccoli        52. carrot         \n",
            " 53. hot dog         54. pizza           55. donut           56. cake           \n",
            " 57. chair           58. sofa            59. pottedplant     60. bed            \n",
            " 61. diningtable     62. toilet          63. tvmonitor       64. laptop         \n",
            " 65. mouse           66. remote          67. keyboard        68. cell phone     \n",
            " 69. microwave       70. oven            71. toaster         72. sink           \n",
            " 73. refrigerator    74. book            75. clock           76. vase           \n",
            " 77. scissors        78. teddy bear      79. hair drier      80. toothbrush     \n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "YOLO Object Detection on Google Colab\n",
        "\n",
        "This script demonstrates how to perform object detection using a pre-trained YOLOv3 model\n",
        "on Google Colab. It allows users to upload an image, specify an object class to detect,\n",
        "and then visualizes the detection results or informs if the object is not supported or not found.\n",
        "\"\"\"\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 1. Download YOLOv3 weights and configuration files ---\n",
        "# These are standard files for YOLOv3. You might need to adjust paths if using a different YOLO version.\n",
        "print(\"Downloading YOLOv3 weights and configuration files...\")\n",
        "!wget -nc https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov3.weights\n",
        "!wget -nc https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
        "!wget -nc https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\n",
        "print(\"Download complete.\")\n",
        "\n",
        "# --- 2. Load YOLO model ---\n",
        "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
        "layer_names = net.getLayerNames()\n",
        "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "# Load COCO class names (YOLOv3 was trained on COCO dataset)\n",
        "with open(\"coco.names\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "print(f\"YOLO model loaded. Supported classes: {len(classes)}\")\n",
        "\n",
        "print(\"\\n--- List of 80 objects that can be detected by this YOLO model (COCO dataset) ---\")\n",
        "# Print classes in a readable format, e.g., columns or numbered list\n",
        "num_columns = 4 # Adjust as needed\n",
        "for i, obj_class in enumerate(classes):\n",
        "    print(f\"{i+1:3d}. {obj_class:<15}\", end=\"\") # 15 for padding\n",
        "    if (i + 1) % num_columns == 0:\n",
        "        print() # New line after every 'num_columns' items\n",
        "if (len(classes) % num_columns != 0): # Print final newline if needed\n",
        "    print()\n",
        "print(\"--------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "# --- 3. Function to perform object detection ---\n",
        "# MODIFIED: Added total_detections_count to the return value\n",
        "def detect_objects(image_path, target_class=None, confidence_threshold=0.5, nms_threshold=0.4):\n",
        "    \"\"\"\n",
        "    Performs object detection on an image using the loaded YOLO model.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the input image.\n",
        "        target_class (str, optional): The specific object class to highlight.\n",
        "                                     If None, all detected objects are shown.\n",
        "        confidence_threshold (float): Minimum confidence to consider a detection.\n",
        "        nms_threshold (float): Non-maximum suppression threshold.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (processed_image, found_target, total_detections_count)\n",
        "               processed_image: Image with bounding boxes and labels (or original if no detections).\n",
        "               found_target: True if the target_class was detected, False otherwise.\n",
        "               total_detections_count: Total number of objects detected overall.\n",
        "    \"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(f\"Error: Could not load image from {image_path}\")\n",
        "        return None, False, 0 # Return 0 detections on error\n",
        "\n",
        "    height, width, channels = img.shape\n",
        "\n",
        "    # Detecting objects\n",
        "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    outs = net.forward(output_layers)\n",
        "\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    found_target = False\n",
        "\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > confidence_threshold:\n",
        "                # Object detected\n",
        "                center_x = int(detection[0] * width)\n",
        "                center_y = int(detection[1] * height)\n",
        "                w = int(detection[2] * width)\n",
        "                h = int(detection[3] * height)\n",
        "\n",
        "                # Rectangle coordinates\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    # Apply Non-Maximum Suppression to remove redundant overlapping boxes\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, confidence_threshold, nms_threshold)\n",
        "    total_detections_count = len(indexes) # Count total detections after NMS\n",
        "\n",
        "    font = cv2.FONT_HERSHEY_PLAIN\n",
        "    colors = np.random.uniform(0, 255, size=(len(classes), 3)) # Generate unique colors for classes\n",
        "\n",
        "    if total_detections_count > 0:\n",
        "        for i in indexes.flatten():\n",
        "            x, y, w, h = boxes[i]\n",
        "            label = str(classes[class_ids[i]])\n",
        "            confidence = str(round(confidences[i], 2))\n",
        "            color = colors[class_ids[i]]\n",
        "\n",
        "            # Only draw if target_class is None (show all) or if it matches the target_class\n",
        "            if target_class is None or label.lower() == target_class.lower():\n",
        "                cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
        "                cv2.putText(img, label + \" \" + confidence, (x, y - 10), font, 1, color, 2)\n",
        "                if target_class is not None and label.lower() == target_class.lower():\n",
        "                    found_target = True\n",
        "    return img, found_target, total_detections_count # Return total detections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFUXIDwiVXrF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "f144863d-0786-4374-e342-a91722619bd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- YOLO Object Detection Demo ---\n",
            "Please upload an image to perform detection.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a937002d-e2b7-434a-bc04-82dc7881b407\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a937002d-e2b7-434a-bc04-82dc7881b407\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# --- 4. Main execution in Colab ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n--- YOLO Object Detection Demo ---\")\n",
        "    print(\"Please upload an image to perform detection.\")\n",
        "\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"No image uploaded. Exiting.\")\n",
        "    else:\n",
        "        for fn in uploaded.keys():\n",
        "            image_path = fn\n",
        "            print(f\"Image '{image_path}' uploaded.\")\n",
        "\n",
        "            while True:\n",
        "                mode_choice = input(\"\\nChoose detection mode:\\n1. Detect a specific object\\n2. Detect all 80 objects\\nType '1', '2', or 'done' to exit: \").strip()\n",
        "\n",
        "                if mode_choice.lower() == 'done':\n",
        "                    break\n",
        "                elif mode_choice == '1':\n",
        "                    user_input_object = input(\"Enter the object you want to detect (e.g., 'car', 'dog', 'person'): \").strip()\n",
        "\n",
        "                    # Check if the requested object is supported by YOLO (i.e., in COCO classes)\n",
        "                    supported_classes_lower = [c.lower() for c in classes]\n",
        "                    if user_input_object.lower() not in supported_classes_lower:\n",
        "                        print(f\"'{user_input_object}' is not a supported object class by this YOLO model (COCO dataset). Please refer to the list above.\")\n",
        "                        continue\n",
        "\n",
        "                    print(f\"Attempting to detect '{user_input_object}' in '{image_path}'...\")\n",
        "                    # Call detect_objects with a specific target_class\n",
        "                    processed_img, target_found, _ = detect_objects(image_path, target_class=user_input_object)\n",
        "\n",
        "                    if processed_img is not None:\n",
        "                        plt.figure(figsize=(10, 8))\n",
        "                        plt.imshow(cv2.cvtColor(processed_img, cv2.COLOR_BGR2RGB))\n",
        "                        plt.axis('off')\n",
        "                        plt.title(f\"Detection Results for '{user_input_object}'\")\n",
        "                        plt.show()\n",
        "\n",
        "                        if target_found:\n",
        "                            print(f\"Success! '{user_input_object}' detected in the image.\")\n",
        "                        else:\n",
        "                            print(f\"'{user_input_object}' was supported but not detected in the image with current confidence settings.\")\n",
        "                    else:\n",
        "                        print(\"Could not process the image for detection.\")\n",
        "\n",
        "                elif mode_choice == '2':\n",
        "                    print(f\"Attempting to detect all 80 objects in '{image_path}'...\")\n",
        "                    # Call detect_objects without a specific target_class\n",
        "                    processed_img, _, total_detections_count = detect_objects(image_path, target_class=None)\n",
        "\n",
        "                    if processed_img is not None:\n",
        "                        plt.figure(figsize=(10, 8))\n",
        "                        plt.imshow(cv2.cvtColor(processed_img, cv2.COLOR_BGR2RGB))\n",
        "                        plt.axis('off')\n",
        "                        plt.title(\"Detection Results (All Supported Objects)\")\n",
        "                        plt.show()\n",
        "\n",
        "                        if total_detections_count > 0:\n",
        "                            print(f\"Detected {total_detections_count} object(s) of supported classes in the image.\")\n",
        "                        else:\n",
        "                            print(\"No objects from the 80 supported classes were detected in the image with current confidence settings.\")\n",
        "                    else:\n",
        "                        print(\"Could not process the image for detection.\")\n",
        "\n",
        "                else:\n",
        "                    print(\"Invalid choice. Please type '1', '2', or 'done'.\")\n",
        "\n",
        "            print(\"\\nDemo finished.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}